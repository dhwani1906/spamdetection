{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "mails are of two types-> spam mails, ham mails\n",
        "\n",
        "-> mail data\n",
        "-> data pre processing\n",
        "-> split data in training data and test data\n",
        "-> and feed the training data to the logistic regression model(best for binary classification problems i.e., 2 classes are there\n",
        "\n",
        "now when a new model arrives the logictic regression model will be predict if it is a spam mail or ham mail\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pdAnov3HYpCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the dependencies"
      ],
      "metadata": {
        "id": "7TPaN3knY4Ix"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewGp1MeWq_qo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "numpy is used to create numpy arrays,\n",
        "\n",
        "and pandas is used to create dataframes(converts csv to more structured data)\n",
        "\n",
        "train_test_split function splits the data into training and testing data\n",
        "\n",
        "TfidfVectorizer CONVERTS THE TEXT DATA into more meaningful data(numeric data) or feature vectors\n",
        "\n",
        "accuracy_store is used to find accuracy of our model when it is tested against the testing data after being trained\n",
        "\n"
      ],
      "metadata": {
        "id": "40I-ttl_bdq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data collection and pre processing"
      ],
      "metadata": {
        "id": "KVEipslAbqpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data from csv file to a pandas data frame\n",
        "raw_mail_data = pd.read_csv(\"/content/mail_data.csv\")"
      ],
      "metadata": {
        "id": "xk9aGZZlbaSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(raw_mail_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khAEqDiMcX8R",
        "outputId": "b77d71d8-1870-4244-948b-439c0f07dbb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Category                                            Message\n",
            "0         ham  Go until jurong point, crazy.. Available only ...\n",
            "1         ham                      Ok lar... Joking wif u oni...\n",
            "2        spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3         ham  U dun say so early hor... U c already then say...\n",
            "4         ham  Nah I don't think he goes to usf, he lives aro...\n",
            "...       ...                                                ...\n",
            "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
            "5568      ham               Will ü b going to esplanade fr home?\n",
            "5569      ham  Pity, * was in mood for that. So...any other s...\n",
            "5570      ham  The guy did some bitching but I acted like i'd...\n",
            "5571      ham                         Rofl. Its true to its name\n",
            "\n",
            "[5572 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#replacing the null values with a null string\n",
        "mail_data = raw_mail_data.where((pd.notnull(raw_mail_data)),'')"
      ],
      "metadata": {
        "id": "p3Jem-PNcjDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the first 5 rows of the dataframe\n",
        "mail_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KpPZoGOXdJ07",
        "outputId": "6658d2ce-fc6a-40b9-c08a-2074677bdbe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Category                                            Message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5f93bcb-af72-47a2-8d35-cb8dc29e3763\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5f93bcb-af72-47a2-8d35-cb8dc29e3763')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5f93bcb-af72-47a2-8d35-cb8dc29e3763 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5f93bcb-af72-47a2-8d35-cb8dc29e3763');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the number of ros and column(size of the dataframe)\n",
        "#O/P -->  (rows, column)\n",
        "mail_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8sBEcvadY0n",
        "outputId": "73e35789-017e-481f-90d8-6477b291e4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5572, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Encoding"
      ],
      "metadata": {
        "id": "Goh-5P_nZuMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#label spam mail as 0 and ham mail as 1\n",
        "mail_data.loc[mail_data['Category'] == 'spam', 'Category',] = 0\n",
        "mail_data.loc[mail_data['Category'] == 'ham', 'Category',] = 1"
      ],
      "metadata": {
        "id": "XDlZUjDOZd5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seperating the data as texts and labels(its like giving x axis value anad y axis value to the model\n",
        "X = mail_data['Message']\n",
        "\n",
        "Y = mail_data['Category']"
      ],
      "metadata": {
        "id": "iDvVIfJ-cmmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf4f4pqmdFzZ",
        "outputId": "b232592c-50b4-4303-b736-4df84af15c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       Go until jurong point, crazy.. Available only ...\n",
            "1                           Ok lar... Joking wif u oni...\n",
            "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3       U dun say so early hor... U c already then say...\n",
            "4       Nah I don't think he goes to usf, he lives aro...\n",
            "                              ...                        \n",
            "5567    This is the 2nd time we have tried 2 contact u...\n",
            "5568                 Will ü b going to esplanade fr home?\n",
            "5569    Pity, * was in mood for that. So...any other s...\n",
            "5570    The guy did some bitching but I acted like i'd...\n",
            "5571                           Rofl. Its true to its name\n",
            "Name: Message, Length: 5572, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV4B_Q88dKGn",
        "outputId": "25ea654f-9ef9-49a8-d78b-da7ec22cbfcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       0\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "5567    0\n",
            "5568    1\n",
            "5569    1\n",
            "5570    1\n",
            "5571    1\n",
            "Name: Category, Length: 5572, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the data in training and testing data"
      ],
      "metadata": {
        "id": "wRDzcOGidYsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 3)"
      ],
      "metadata": {
        "id": "sDnmaJwddPuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "x and y will be splited in 2 parts training and testing data \n",
        "\n",
        "after splitting x all the y data will  split correspondingly\n",
        "\n",
        "the X_train, X_test, Y_train, Y_test are arrays\n",
        "\n",
        "training data is more than testing data\n",
        "train_test_split(X, Y, test_size = 0.2) will split the data and test size = 0.2 will split the 20% of datA as testing data and remaining 80% of data as training data\n",
        "\n",
        "each time we use the train_test_split function it';ll split the data in different ways, if we want the data to be splitted in the same way then we mention the random state 3 parameter if we pass random state parater value as 2 it'll slpit it in a different manner"
      ],
      "metadata": {
        "id": "1baNelhUdv-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXAkbYNaeKgU",
        "outputId": "f99c2688-3a3b-4929-f165-3bf35e7049e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572,)\n",
            "(4457,)\n",
            "(1115,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here (5572,) secon parameter is empty that means there is only one column as shape gives output as(rows, column)\n",
        "\n",
        "5572 -> total data(rows)\n",
        "\n",
        "4457 -> training data\n",
        "\n",
        "1115 -> testing data"
      ],
      "metadata": {
        "id": "sfdqpfTdgYWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "N4ylIewAhAVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transform the text data to feature vectors tha can be used as input to the logistic regression model\n",
        "#feature vectors are basically numeric values\n",
        "feature_extraction = TfidfVectorizer(min_df = 1, stop_words='english', lowercase='True')\n",
        "\n",
        "X_train_features = feature_extraction.fit_transform(X_train)\n",
        "X_test_features = feature_extraction.transform(X_test)\n",
        "\n",
        "#convert Y_train and Y_test values as intergers bcz though the value is 0 and 1 but it is in the form of objects/strings and \n",
        "#we don't want it to get append so doing this will help(ease) the model to work\n",
        "\n",
        "Y_train = Y_train.astype('int')\n",
        "Y_test = Y_test.astype('int')"
      ],
      "metadata": {
        "id": "fzDVPAsegLGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this TfidfVectorization() looks at the data and look for the words(free, offer, discount etc) in the documents(data set) and if it is repeated several times it will get some values based on how many times the word is being repeated and give the value(importance score)\n",
        "\n",
        "now the logistic regression model will link all these wordsto get some numerical value and they will be related to the label spam which is zero\n",
        "\n",
        "and other mails will getsome other score values and will  be linked to ham mails\n",
        "\n",
        "so the difference betweeen spam and ham mails is identified by going through these values \n",
        "\n",
        "\n",
        "PARAMETERS\n",
        "\n",
        "min_df = 1  ---> \n",
        "\n",
        "if the score is more than 1 e need to ignore it as we only have 2 categories 0 & 1 so if the word is repeated only one time we don't care about it bcz it won't be that important for our prediction\n",
        "\n",
        "this score will be given to all the words individually\n",
        "\n",
        "\n",
        "stop_words = 'english'--->\n",
        "\n",
        "\n",
        "did, is, the etc are called stop words bcz they don't hold much value and will be ignored by the logistic regression(LR)\n",
        "\n",
        "\n",
        "lowercase = 'true'--->\n",
        "\n",
        "\n",
        "\n",
        "all the letters will be changed to lowercase as it will be easy for processing\n",
        "\n",
        "\n",
        "X_train_feature will store the numeric value after the x_train data is converted into feature vectors same will be done with x test as they both contain messages\n",
        "\n",
        "while y train and test won't be converted bcz they are already numbers(0&1 spam or ham)\n",
        "\n",
        "\n",
        "\n",
        "two things are happening here\n",
        "1. fitting the data in Vectorisor\n",
        "2. converting all the data into feature vectors which is basiclll numerical values\n",
        "\n",
        "*** we don't write extraction.fit_transform in x_ test bczwe don't wan our model to look at the test data"
      ],
      "metadata": {
        "id": "RCxb8KAohuqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJr1RDUJnOvv",
        "outputId": "a77c2121-0622-4823-d149-285386db7064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3075                  Don know. I did't msg him recently.\n",
            "1787    Do you know why god created gap between your f...\n",
            "1614                         Thnx dude. u guys out 2nite?\n",
            "4304                                      Yup i'm free...\n",
            "3266    44 7732584351, Do you want a New Nokia 3510i c...\n",
            "                              ...                        \n",
            "789     5 Free Top Polyphonic Tones call 087018728737,...\n",
            "968     What do u want when i come back?.a beautiful n...\n",
            "1667    Guess who spent all last night phasing in and ...\n",
            "3321    Eh sorry leh... I din c ur msg. Not sad alread...\n",
            "1688    Free Top ringtone -sub to weekly ringtone-get ...\n",
            "Name: Message, Length: 4457, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QV2FXkWnSn9",
        "outputId": "cd7fd1fe-bf70-43c6-e7c8-b988603c6615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 5413)\t0.6198254967574347\n",
            "  (0, 4456)\t0.4168658090846482\n",
            "  (0, 2224)\t0.413103377943378\n",
            "  (0, 3811)\t0.34780165336891333\n",
            "  (0, 2329)\t0.38783870336935383\n",
            "  (1, 4080)\t0.18880584110891163\n",
            "  (1, 3185)\t0.29694482957694585\n",
            "  (1, 3325)\t0.31610586766078863\n",
            "  (1, 2957)\t0.3398297002864083\n",
            "  (1, 2746)\t0.3398297002864083\n",
            "  (1, 918)\t0.22871581159877646\n",
            "  (1, 1839)\t0.2784903590561455\n",
            "  (1, 2758)\t0.3226407885943799\n",
            "  (1, 2956)\t0.33036995955537024\n",
            "  (1, 1991)\t0.33036995955537024\n",
            "  (1, 3046)\t0.2503712792613518\n",
            "  (1, 3811)\t0.17419952275504033\n",
            "  (2, 407)\t0.509272536051008\n",
            "  (2, 3156)\t0.4107239318312698\n",
            "  (2, 2404)\t0.45287711070606745\n",
            "  (2, 6601)\t0.6056811524587518\n",
            "  (3, 2870)\t0.5864269879324768\n",
            "  (3, 7414)\t0.8100020912469564\n",
            "  (4, 50)\t0.23633754072626942\n",
            "  (4, 5497)\t0.15743785051118356\n",
            "  :\t:\n",
            "  (4454, 4602)\t0.2669765732445391\n",
            "  (4454, 3142)\t0.32014451677763156\n",
            "  (4455, 2247)\t0.37052851863170466\n",
            "  (4455, 2469)\t0.35441545511837946\n",
            "  (4455, 5646)\t0.33545678464631296\n",
            "  (4455, 6810)\t0.29731757715898277\n",
            "  (4455, 6091)\t0.23103841516927642\n",
            "  (4455, 7113)\t0.30536590342067704\n",
            "  (4455, 3872)\t0.3108911491788658\n",
            "  (4455, 4715)\t0.30714144758811196\n",
            "  (4455, 6916)\t0.19636985317119715\n",
            "  (4455, 3922)\t0.31287563163368587\n",
            "  (4455, 4456)\t0.24920025316220423\n",
            "  (4456, 141)\t0.292943737785358\n",
            "  (4456, 647)\t0.30133182431707617\n",
            "  (4456, 6311)\t0.30133182431707617\n",
            "  (4456, 5569)\t0.4619395404299172\n",
            "  (4456, 6028)\t0.21034888000987115\n",
            "  (4456, 7154)\t0.24083218452280053\n",
            "  (4456, 7150)\t0.3677554681447669\n",
            "  (4456, 6249)\t0.17573831794959716\n",
            "  (4456, 6307)\t0.2752760476857975\n",
            "  (4456, 334)\t0.2220077711654938\n",
            "  (4456, 5778)\t0.16243064490100795\n",
            "  (4456, 2870)\t0.31523196273113385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the ML model"
      ],
      "metadata": {
        "id": "jHmlMX5Gn1Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Model"
      ],
      "metadata": {
        "id": "OVuS9OjSn56Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the LR model in model variable\n",
        "model = LogisticRegression()"
      ],
      "metadata": {
        "id": "K5B6C4HDnoCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the LR model with the training data\n",
        "#X_train_features ---> the feature vectors of the x tran i.e., msgs\n",
        "#Y_train ---> corresponding 0, 1 value \n",
        "model.fit(X_train_features, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_3mprjpoFGZ",
        "outputId": "58ce4aea-98bf-450a-a05a-d14528233f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now the model is trained and it we will give and mail to it it will be able to categorise it into spam or ham mail but first we have to evaluate it"
      ],
      "metadata": {
        "id": "D4VIOuLLo7jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the trained model"
      ],
      "metadata": {
        "id": "6FRopKEipKEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on training data only giving the X_train_features and \n",
        "#asking the model to predict the Y_ train value i.e., is the mail spam or ham (0 or 1)\n",
        "\n",
        "prediction_on_training_data = model.predict(X_train_features) #corresponding Y_train is stored in prediction_on_training_data\n",
        "\n",
        "accuracy_on_training_data = accuracy_score(Y_train, prediction_on_training_data)  #accuracy_score(real value, predicted value)\n"
      ],
      "metadata": {
        "id": "ZTejSlzooo3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy on training data = ', accuracy_on_training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kknoI-GFqQ4J",
        "outputId": "73e47be4-0080-4936-e51d-95d5fac77536"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training data =  0.9670181736594121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "that means accuracy is 96.7% \n",
        "\n",
        "we can say if the accuracy score is more than 75/5 than it is a good model and if >95% then it is working really well"
      ],
      "metadata": {
        "id": "W9VBZ_DUqmzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction on testing data only giving the X_test_features and \n",
        "#asking the model to predict the Y_ test value i.e., is the mail spam or ham (0 or 1)\n",
        "\n",
        "prediction_on_testing_data = model.predict(X_test_features) #corresponding Y_test is stored in prediction_on_testing_data\n",
        "\n",
        "accuracy_on_testing_data = accuracy_score(Y_test, prediction_on_testing_data)  #accuracy_score(real value, predicted value)\n"
      ],
      "metadata": {
        "id": "9LykTWfDqgX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy on testing data = ', accuracy_on_testing_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypvkmwRJrdWT",
        "outputId": "c9362221-80c7-43f8-dd54-2a8ca9ad781a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on testing data =  0.9659192825112107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in some cases the model may overfit(performs well on training data but not on testing data) that is why we tested it on both training and testing data"
      ],
      "metadata": {
        "id": "QWTvV0vur4WW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a predictive system"
      ],
      "metadata": {
        "id": "z42pIKD1scC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_mail = [\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\"]\n",
        "#converting text to feature vectors\n",
        "input_data_features = feature_extraction.transform(input_mail)\n",
        "\n",
        "#making predictions\n",
        "predictions = model.predict(input_data_features)\n",
        "print(predictions)\n",
        "\n",
        "if (predictions[0]==1):\n",
        "  print('Ham mail')\n",
        "else:\n",
        "  print('Spam mail!!!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gn-bbrernKh",
        "outputId": "a1a02669-e78b-468a-f35c-9a741906c8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "Ham mail\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predictions comes in a list"
      ],
      "metadata": {
        "id": "1nY4CQe3uBAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the trained model"
      ],
      "metadata": {
        "id": "ctsQwaTHCccw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "oCXAp5BGCgge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'trained_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "W1Boq3rxCiqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the saved model\n",
        "loaded_model = pickle.load(open('trained_model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "9R5ys_X0Dzob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_mail = [\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\"]\n",
        "#converting text to feature vectors\n",
        "input_data_features = feature_extraction.transform(input_mail)\n",
        "\n",
        "#making predictions\n",
        "predictions = loaded_model.predict(input_data_features)\n",
        "print(predictions)\n",
        "\n",
        "if (predictions[0]==1):\n",
        "  print('This mail is a Ham mail')\n",
        "else:\n",
        "  print('This mail is a Spam mail!!!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiL1jJd1EKRG",
        "outputId": "18bd70f2-023c-4bca-d41b-6b6f32f1c485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "This mail is a Ham mail\n"
          ]
        }
      ]
    }
  ]
}